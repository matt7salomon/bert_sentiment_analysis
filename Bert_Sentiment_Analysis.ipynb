{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0ecb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (4.44.2)\n",
      "Requirement already satisfied: datasets in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: requests in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: pandas in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: aiohttp in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: multiprocess in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: xxhash in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: opencv-python in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: seaborn in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (22.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.40.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: gensim in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (4.3.3)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Requirement already satisfied: tensorflow_datasets in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (4.9.6)\n",
      "Requirement already satisfied: tensorflow_probability in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (0.24.0)\n",
      "Requirement already satisfied: tf-keras in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: pyarrow in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (15.0.0)\n",
      "Requirement already satisfied: absl-py in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (2.28.1)\n",
      "Requirement already satisfied: simple-parsing in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.5)\n",
      "Requirement already satisfied: termcolor in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Requirement already satisfied: promise in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: toml in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: immutabledict in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (4.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (4.64.1)\n",
      "Requirement already satisfied: wrapt in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Requirement already satisfied: etils[enp,epath,epy,etree]>=1.6.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (1.7.0)\n",
      "Requirement already satisfied: numpy in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (1.23.5)\n",
      "Requirement already satisfied: dm-tree in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.10.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_probability) (1.16.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_probability) (2.2.1)\n",
      "Requirement already satisfied: decorator in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_probability) (5.1.1)\n",
      "Requirement already satisfied: gast>=0.3.2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow_probability) (0.6.0)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tf-keras) (2.17.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow_datasets) (4.12.2)\n",
      "Requirement already satisfied: importlib_resources in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow_datasets) (6.4.4)\n",
      "Requirement already satisfied: zipp in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow_datasets) (3.20.1)\n",
      "Requirement already satisfied: fsspec in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow_datasets) (2023.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.14)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.1)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.66.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: packaging in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (22.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.5.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (65.6.3)\n",
      "Requirement already satisfied: docstring-parser~=0.15 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from simple-parsing->tensorflow_datasets) (0.16)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: rich in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.0.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\n",
      "Requirement already satisfied: transformers in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (4.44.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mattsalomon/miniconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets\n",
    "!pip install opencv-python\n",
    "!pip install seaborn\n",
    "!pip install gensim\n",
    "!pip install tensorflow_datasets tensorflow_probability tf-keras\n",
    "!pip install --upgrade transformers\n",
    "# !pip install google-colab\n",
    "#!pip install protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fd872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION']='python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75c11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf### models\n",
    "import numpy as np### math computations\n",
    "import matplotlib.pyplot as plt### plotting bar chart\n",
    "import sklearn### machine learning library\n",
    "import cv2## image processing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
    "import seaborn as sns### visualizations\n",
    "import datetime # For Datetime Functions\n",
    "import pathlib # handling files and paths on your operating system\n",
    "import io # dealing with various types of I/O\n",
    "import os \n",
    "import re # for Regular Expressions\n",
    "import string\n",
    "import time\n",
    "from numpy import random\n",
    "import gensim.downloader as api # to download pre-trained model datasets and word embeddings from Gensim's repository\n",
    "from PIL import Image # manipulating images, resizing, cropping, adding text\n",
    "import tensorflow_datasets as tfds # Tf Datasets\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import (Dense,Flatten,InputLayer,BatchNormalization,\n",
    "                                     Dropout,Input,LayerNormalization)\n",
    "from tensorflow.keras.losses import (BinaryCrossentropy,CategoricalCrossentropy,\n",
    "                                    SparseCategoricalCrossentropy)\n",
    "from tensorflow.keras.metrics import (Accuracy,TopKCategoricalAccuracy,\n",
    "                                 CategoricalAccuracy, SparseCategoricalAccuracy)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from google.colab import drive\n",
    "# from google.colab import files\n",
    "from datasets import load_dataset\n",
    "from transformers import (BertTokenizerFast,TFBertTokenizer,BertTokenizer,RobertaTokenizerFast,\n",
    "                          DataCollatorWithPadding,TFRobertaForSequenceClassification,TFBertForSequenceClassification,\n",
    "                          TFBertModel,create_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b38131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=8\n",
    "dataset_id='imdb'\n",
    "dataset = load_dataset(dataset_id) # load_dataset is a function of datasets library of HuggingFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210616a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ac99f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({'text':dataset['train'][:5]['text'],'label':dataset['train'][:5]['label']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ab2787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattsalomon/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_id=\"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c86fdbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'weather',\n",
       " 'of',\n",
       " 'today',\n",
       " 'is',\n",
       " 'great',\n",
       " '!',\n",
       " 'z',\n",
       " '##w',\n",
       " '##p',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_1='The Weather of Today is Gréat! zwp'\n",
    "test_input_2='How are you doing?'\n",
    "inputs=[test_input_1,test_input_2]\n",
    "\n",
    "tokenizer.tokenize(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8584391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 1996, 4633, 1997, 2651, 2003, 2307, 999, 1062, 2860, 2361, 102], [101, 2129, 2024, 2017, 2725, 1029, 102, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "output=tokenizer(inputs,padding=True,truncation=True,max_length=128)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1683f1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] the weather of today is great! zwp [SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8e15d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] how are you doing? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f850f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"],padding=True,truncation=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f45c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba34948350f40878783fd9f26795e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7804f7202604ccc95133aee43bbdbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d74ae0adb24894bbb3629e4c9af645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce78ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1045, 12524, 1045, 2572, 8025, 1011, 375...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1000, 1045, 2572, 8025, 1024, 3756, 1000...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2065, 2069, 2000, 4468, 2437, 2023, 2828...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2023, 2143, 2001, 2763, 4427, 2011, 2643...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2821, 1010, 2567, 1012, 1012, 1012, 2044...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0   \n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0   \n",
       "2  If only to avoid making this type of film in t...      0   \n",
       "3  This film was probably inspired by Godard's Ma...      0   \n",
       "4  Oh, brother...after hearing about this ridicul...      0   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 1045, 12524, 1045, 2572, 8025, 1011, 375...   \n",
       "1  [101, 1000, 1045, 2572, 8025, 1024, 3756, 1000...   \n",
       "2  [101, 2065, 2069, 2000, 4468, 2437, 2023, 2828...   \n",
       "3  [101, 2023, 2143, 2001, 2763, 4427, 2011, 2643...   \n",
       "4  [101, 2821, 1010, 2567, 1012, 1012, 1012, 2044...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'text':tokenized_dataset['train'][:5]['text'],\n",
    "    'label':tokenized_dataset['train'][:5]['label'],\n",
    "    'input_ids':tokenized_dataset['train'][:5]['input_ids'],\n",
    "    'token_type_ids':tokenized_dataset['train'][:5]['token_type_ids'],\n",
    "    'attention_mask':tokenized_dataset['train'][:5]['attention_mask']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c6bb8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "\n",
    "tf_train_dataset = tokenized_dataset[\"train\"].to_tf_dataset(\n",
    "    columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c52ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataset\n",
    "\n",
    "tf_val_dataset = tokenized_dataset[\"test\"].to_tf_dataset(\n",
    "    columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e8dc915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_positions(dataset):\n",
    "    return {'input_ids':dataset['input_ids'],\n",
    "          'token_type_ids':dataset['token_type_ids'],\n",
    "          'attention_mask':dataset['attention_mask'],},dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "712948e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset=tf_train_dataset.map(swap_positions).prefetch(tf.data.AUTOTUNE)\n",
    "tf_val_dataset=tf_val_dataset.map(swap_positions).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc12697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(8, 512), dtype=int64, numpy=\n",
      "array([[  101,  2023,  3185, ...,     0,     0,     0],\n",
      "       [  101,  4209,  2054, ...,  1997,  1037,   102],\n",
      "       [  101,  2019, 18691, ..., 10363,  1998,   102],\n",
      "       ...,\n",
      "       [  101,  1045,  1005, ...,     0,     0,     0],\n",
      "       [  101,  3532,  3772, ...,  2043,  2027,   102],\n",
      "       [  101,  2012,  2560, ...,     0,     0,     0]])>, 'token_type_ids': <tf.Tensor: shape=(8, 512), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(8, 512), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>}, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([0, 1, 1, 0, 0, 1, 0, 0])>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 00:36:23.846128: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for i in tf_train_dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4209d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       multiple                  0 (unused)\n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109483009 (417.64 MB)\n",
      "Trainable params: 109483009 (417.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "431a7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "batches_per_epoch = len(tokenized_dataset[\"train\"]) // BATCH_SIZE\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8ab2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5,num_warmup_steps=0, num_train_steps=total_train_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49d0d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],)\n",
    "    #run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ba54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  73/1000 [=>............................] - ETA: 2:12:39 - loss: 0.7034 - accuracy: 0.5788"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    tf_train_dataset.take(1000),\n",
    "    validation_data=tf_val_dataset,\n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5980ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f3a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"this movie looks very interesting, i love the fact that the actors do a great job in showing how people lived in the 18th century, which wasn't very good at all. But atleast this movie recreates this scenes! \",\n",
    "                    \"very good start, but movie started becoming uninteresting at some point though initially i thought it would have been much more fun. There was too much background noise, but later on towards the middle of the movie, my favorite character got in and he did a great job, so over \"], padding=True,return_tensors=\"tf\")\n",
    "\n",
    "logits = model(**inputs).logits\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax to logits to get probabilities\n",
    "probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "# Print the probabilities\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fedd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_python310",
   "language": "python",
   "name": "tf_python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
